{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from collections import Counter\n",
    "import little_mallet_wrapper\n",
    "import seaborn\n",
    "import glob\n",
    "from pathlib import Path\n",
    "#LOADING EVERYTHING\n",
    "directory = \"/Users/joshs/Desktop/Spring 2021/HUM346/wsj-nyt-oped/NYTimes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joshs/opt/anaconda3/lib/python3.8/site-packages/pynytimes/api.py:630: UserWarning: Asking for a lot of results, because of rate limits it can take a while.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Importing stuff from NYTIMES\n",
    "from pynytimes import NYTAPI\n",
    "import urllib3, json, datetime\n",
    "nyt = NYTAPI(\"nKBpzKBvOYipTxZf1T1NwCsVeXad5xoE\", parse_dates=True)\n",
    "articles = nyt.article_search(\n",
    "    results = 500,\n",
    "    dates = {\n",
    "        \"begin\": datetime.datetime(2020, 10, 1),\n",
    "        \"end\": datetime.datetime(2020, 10, 30)\n",
    "    },\n",
    "    options = {\n",
    "        \"sources\": [\n",
    "            \"New York Times\",\n",
    "        ],\n",
    "        \"news_desk\": [\n",
    "            \"OpEd\",\n",
    "            \"Editorial\"\n",
    "            \n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing articles to be saved\n",
    "for article in articles:\n",
    "    \n",
    "    text_file = open(f\"{article['abstract']}.txt\", \"w+\")\n",
    "    n = text_file.write(article['lead_paragraph'] + \" \\n\")\n",
    "    text_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting text into all lowercase\n",
    "def split_into_words(any_chunk_of_text):\n",
    "    lowercase_text = any_chunk_of_text.lower()\n",
    "    split_words = re.split(\"\\W+\", lowercase_text) \n",
    "    return split_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining all data together IT SHOULD WORK NOW BUT WAS NOT WORKING EARLIER\n",
    "files = glob.glob(f\"{directory}/*.txt\")\n",
    "training_data = []\n",
    "for file in files:\n",
    "    text = open(file).read()\n",
    "    processed_text = little_mallet_wrapper.process_string(text)\n",
    "    training_data.append(processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_texts = []\n",
    "for file in files:\n",
    "    text = open(file, encoding='utf-8').read()\n",
    "    original_texts.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-7-bc11a219b860>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 18\u001B[0;31m \u001B[0mall_the_words\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msplit_into_words\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfull_text\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     19\u001B[0m \u001B[0mmeaningful_words\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mword\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mword\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mall_the_words\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mword\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mstopwords\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[0mmeaningful_words_tally\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mCounter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmeaningful_words\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-3-f61109e12f30>\u001B[0m in \u001B[0;36msplit_into_words\u001B[0;34m(any_chunk_of_text)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m#splitting text into all lowercase\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0msplit_into_words\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0many_chunk_of_text\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m     \u001B[0mlowercase_text\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0many_chunk_of_text\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlower\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m     \u001B[0msplit_words\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mre\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"\\W+\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlowercase_text\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0msplit_words\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'list' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "\n",
    "full_text = training_data\n",
    "number_of_desired_words = 10\n",
    "# Manipulate and Analyze File\n",
    "stopwords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours',\n",
    "'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers',\n",
    " 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves',\n",
    " 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are',\n",
    " 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does',\n",
    " 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until',\n",
    " 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into',\n",
    " 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down',\n",
    " 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here',\n",
    " 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\n",
    " 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so',\n",
    " 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', 've', 'll', 'amp']\n",
    "\n",
    "\n",
    "all_the_words = split_into_words(full_text)\n",
    "meaningful_words = [word for word in all_the_words if word not in stopwords]\n",
    "meaningful_words_tally = Counter(meaningful_words)\n",
    "most_frequent_meaningful_words = meaningful_words_tally.most_common(number_of_desired_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('many', 11),\n",
       " ('year', 9),\n",
       " ('new', 9),\n",
       " ('one', 9),\n",
       " ('world', 8),\n",
       " ('pandemic', 8),\n",
       " ('months', 8),\n",
       " ('coronavirus', 7),\n",
       " ('us', 7),\n",
       " ('states', 6)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_frequent_meaningful_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path_to_mallet = '/Users/joshs/mallet-2.0.8/bin/mallet'\n",
    "num_topics = 10\n",
    "    \n",
    "#Change to your desired output directory\n",
    "output_directory_path = '/Users/joshs/Desktop/Spring 2021/HUM346/wsj-nyt-oped/NYTimes/topic-model-output'\n",
    "\n",
    "#No need to change anything below here\n",
    "Path(f\"{output_directory_path}\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "path_to_training_data           = f\"{output_directory_path}/training.txt\"\n",
    "path_to_formatted_training_data = f\"{output_directory_path}/mallet.training\"\n",
    "path_to_model                   = f\"{output_directory_path}/mallet.model.{str(num_topics)}\"\n",
    "path_to_topic_keys              = f\"{output_directory_path}/mallet.topic_keys.{str(num_topics)}\"\n",
    "path_to_topic_distributions     = f\"{output_directory_path}/{str(num_topics)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Documents: 328\n",
      "Mean Number of Words per Document: 30.7\n",
      "Vocabulary Size: 4306\n"
     ]
    }
   ],
   "source": [
    "little_mallet_wrapper.print_dataset_stats(training_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing data...\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "#Importing Data\n",
    "little_mallet_wrapper.import_data(path_to_mallet,\n",
    "                path_to_training_data,\n",
    "                path_to_formatted_training_data,\n",
    "                training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training topic model...\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "#Training Data Doesnt seem to work?\n",
    "little_mallet_wrapper.train_topic_model(path_to_mallet,\n",
    "                      path_to_formatted_training_data,\n",
    "                      path_to_model,\n",
    "                      path_to_topic_keys,\n",
    "                      path_to_topic_distributions,\n",
    "                      num_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✨Topic 0✨\n",
      "\n",
      "['two', 'could', 'one', 'might', 'national', 'decades', 'came', 'big', 'NUMs', 'security', 'argument', 'listen', 'talk', 'even', 'ever', 'idea', 'department', 'human', 'device', 'mobile']\n",
      "\n",
      "✨Topic 1✨\n",
      "\n",
      "['NUM', 'coronavirus', 'one', 'americans', 'first', 'pandemic', 'get', 'care', 'health', 'covid', 'time', 'year', 'days', 'early', 'nation', 'public', 'even', 'say', 'face', 'case']\n",
      "\n",
      "✨Topic 2✨\n",
      "\n",
      "['court', 'democrats', 'supreme', 'would', 'barrett', 'senate', 'coney', 'amy', 'political', 'power', 'republicans', 'president', 'judge', 'republican', 'conservative', 'system', 'win', 'confirmation', 'constitution', 'five']\n",
      "\n",
      "✨Topic 3✨\n",
      "\n",
      "['people', 'know', 'black', 'home', 'among', 'nearly', 'take', 'things', 'death', 'always', 'around', 'old', 'largest', 'used', 'others', 'back', 'point', 'half', 'mother', 'online']\n",
      "\n",
      "✨Topic 4✨\n",
      "\n",
      "['trump', 'president', 'donald', 'biden', 'joe', 'debate', 'presidential', 'last', 'week', 'election', 'question', 'back', 'never', 'going', 'thought', 'news', 'opinion', 'well', 'said', 'think']\n",
      "\n",
      "✨Topic 5✨\n",
      "\n",
      "['new', 'america', 'york', 'would', 'right', 'house', 'white', 'also', 'city', 'way', 'politics', 'businesses', 'american', 'love', 'large', 'history', 'actually', 'man', 'future', 'ambition']\n",
      "\n",
      "✨Topic 6✨\n",
      "\n",
      "['like', 'election', 'american', 'long', 'country', 'much', 'democracy', 'may', 'party', 'even', 'good', 'federal', 'vote', 'presidency', 'political', 'society', 'end', 'administration', 'washington', 'war']\n",
      "\n",
      "✨Topic 7✨\n",
      "\n",
      "['many', 'states', 'world', 'united', 'months', 'life', 'government', 'media', 'economic', 'across', 'month', 'country', 'millions', 'year', 'women', 'moment', 'night', 'children', 'fact', 'recent']\n",
      "\n",
      "✨Topic 8✨\n",
      "\n",
      "['NUM', 'years', 'state', 'still', 'see', 'tax', 'ago', 'times', 'four', 'men', 'means', 'town', 'recently', 'hospital', 'business', 'money', 'scale', 'known', 'candidate', 'anti']\n",
      "\n",
      "✨Topic 9✨\n",
      "\n",
      "['part', 'article', 'time', 'day', 'today', 'newsletter', 'receive', 'sign', 'asked', 'school', 'far', 'found', 'thursdays', 'tuesdays', 'debatable', 'got', 'didn', 'left', 'person', 'every']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topics = little_mallet_wrapper.load_topic_keys(path_to_topic_keys)\n",
    "\n",
    "for topic_number, topic in enumerate(topics):\n",
    "    print(f\"✨Topic {topic_number}✨\\n\\n{topic}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}